\documentclass[format=acmtog,natbib=false]{acmart}
\usepackage[backend=biber]{biblatex}
\usepackage{multicol}
\usepackage{tikz}
\addbibresource{refs.bib}

\title{Asychronous Smoothed Particle Hydrodynamics}
\author{Andrew Pregent}
\date{}

\begin{document}
\maketitle{}
\section{Abstract}

In this paper, a new method for parallelizing smooth-particle hydrodynamics using CUDA on the GPU will be presented, building upon asychronous SPH. The method will then be evaluated for performance against single and multi-core implementations, and its accuracy will be compared to a commercial simulation package.

\section{Introduction}

Particle-based fluid simulations are a difficult problem to parallelize efficiently. Similar to the notorious N-Body problem, particles in CFD simulations may potentially interact with any other particle in the system, at any point in time. The random access which this requires is particularly unfriendly to GPUs, which are typically optimized for streamed memory. To make matters worse, to obtain any meaningful results requires not only a very large number of particles (typically on the order of millions) but the calculations must be done at extremely small time-scales in order to ensure the stability of the system. To this end, a large amount of research has been done on attempting to reduce the computational time required.

\section{Literature Review}

Computational Fluid Dynamics is predominantly concerned with the integration of the Navier-Stokes equations through time. These equations rely on the continuum hypothesis of a fluid, which is the assumption that despite the true nature of fluids being a result of their molecular interactions, the macroscopic behaviours of a fluid can be  predicted with sufficient accuracy with smooth vector fields.

Fluid simulation can be broadly grouped into two categories. Eulerian simulations observe physical quantities which move past fixed locations in space. The use of regular grids is often employed, however some methods also use meshes instead. Lagrangian simulations track the movement of physical quantities through the flow of the fluid. There also exist hybrid approaches which attempt to make use of both paradigms.

% Method

Smoothed Particle Hydrodynamics (SPH) is a Lagrangian simulation method first proposed independently by L.B. Lucy\cite{lucy1977numerical} and R.A. Gingold and J.J. Monaghan\cite{gingold1977smoothed} for simulations in astrophysics. J.J. Monaghan later extended the method to free surface flows\cite{monaghan1994simulating}. Refer to Ting Ye, et al. for a modern review of various advances in the method.

% Time Step

Mathieu Desbrun and Marie-Paule Gascuel applied the Courant-Friedrichs-Lewy criterion to SPH, providing an upper bound on the time step based on the kernel support size and the maximum particle velocity\cite{desbrun1996smoothed}. This means that in practice the time step must often be very small in order for the simulation to remain stable. Predictive Corrective Incompressive SPH (PCISPH) attempts to address this problem for incompressible fluids such as water, where the problem is exacerbated by the high stiffness required in the equation of state (EOS)\cite{solenthaler2009predictive}.

Another approach is to avoid a global time-step altogether. Prashant Goswami and Christopher Batty propose segmenting the time-step by spatial chunks.\cite{goswami2014regional}. Asychronous SPH allows every particle to have its own time frame\cite{reinhardt2017fully}\cite{ban2018adaptively}\cite{desbrun1996smoothed}. This is more efficient when there are only a few fast particles, as is often the case. Reinhardt also suggest using multiple queues in parallel, a method due to Kale and Lew, though they are unsure if this will scale well in practice on the GPU.\cite{reinhardt2017fully}\cite{kale2007parallel}.

% Parallel

Much research has been done to bring SPH to the GPU. Much of the difficulty lies in efficiently searching a fixed distance neighborhood of each particle, since a brute force search of every particle pair is infeasible. The work of Ihmsen et al. provided much of the groundwork with an early parallel implementation.\cite{ihmsen2011parallel} For this search they used a Z-index sort, a space filling curve which provides a cache-friendly ordering for the particles. Amada et al. present a partial GPU implementation which relies on the CPU for the neighborhood search, providing the information to the GPU as a texture.\cite{amada2004particle} Harada et al. present an early fully GPU implementation\cite{harada2007smoothed}. Later H{\'e}rault make use of the programmable pipeline to create a CUDA implementation\cite{herault2010sph}, which they later released as open source\cite{gpusph}. Finally, Rustico et al. extend this to multiple GPUs.\cite{rustico2012journey}

The neighborhood search has also garnered interest on its own. Ohno, Nitta and Nakai look at optimizing the neighborhood search for the GPU. Recently, Gro{\ss} and K{\"o}ster look at utilizing modern features of GPUs\cite{gross2019fast}. In particular, they leverage atomic memory synchronization between work groups in order to optimize the search further.

\section{Problem Statement}
\section{Method}

All particles in the simulation start at the same age, and ages of particles are tracked individually. A particle ages as it steps forward in time. All the particles in a cell are stepped forward in time at once. The time-step is  determined by the fastest particle in the cell, using the CFL condition. This ensures that the simulation remains stable.

Previous methods of asychronous SPH integrate each particle forward in time individually. However, this was found to be prohibitively expensive to implement on the GPU. Instead, all the particles in a cell are integrated at once. This allows us to re-use the backtracked neighborhood surrounding the cell for each particle in the cell, greatly reducing the overhead of backtracking while still allowing different areas of the simulation to be integrated at different rates. 

A cell is only updated if it is younger than all of its neighboring cells. This ensures that no region of the simulation is stepped too far ahead of other regions. This also ensures that it is never necessary to extrapolate the location of particles, only interpolation of physical values is required to bring a neighborhood of particles to the same frame of reference in time, increasing the stability of the simulation.

\begin{figure}[H]
\begin{tikzpicture}
\draw [->] (3.2,2.8) -- (4.4,2.9);
\draw[fill=white] (3.2,2.8) circle (0.2cm);
\draw[step=2cm] (0,0) grid (6,6);
\end{tikzpicture}
\label{fig:}
\caption{The youngest particle determines the time step of a cell.}
\end{figure}

\section{Results}
\section{Conclusion}
\section{References}

\printbibliography
\end{document}